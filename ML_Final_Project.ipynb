{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-QtQEzYoJ-1",
        "outputId": "963bab02-346f-4da6-d268-00aa216c1543"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (1.24.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (2.1.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (9.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\fruxi\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pk\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "jBr_v6u3pafB"
      },
      "outputs": [],
      "source": [
        "np.seterr(all='ignore')\n",
        "def tanH(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def deriv_tanH(fx):\n",
        "    return 1 - fx ** 2\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def deriv_sigmoid(fx):\n",
        "    return fx * (1 - fx)\n",
        "\n",
        "\n",
        "def ReLU(Z):\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "\n",
        "def deriv_ReLU(Z):\n",
        "    return Z > 0\n",
        "\n",
        "\n",
        "# def softmax(Z):\n",
        "#     Z = np.exp(Z)\n",
        "#     return (Z / np.sum(Z))\n",
        "\n",
        "# correct solution:\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0) # only difference\n",
        "\n",
        "def clip_gradients(gradient, maxValue):\n",
        "    \"\"\"Clip the gradient to between -maxValue and maxValue.\"\"\"\n",
        "    return np.clip(gradient, -maxValue, maxValue)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    # Clip predicted values to avoid numerical instability\n",
        "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "\n",
        "    # Compute cross-entropy loss\n",
        "    loss = -np.sum(y_true * np.log(y_pred))\n",
        "\n",
        "    return loss\n",
        "\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, 10))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "\n",
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    return np.sum(predictions == Y) / Y.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "7UCAM8o3-k2H"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    NEURONS = 0\n",
        "    UNIFORM_LOW = 0\n",
        "    UNIFORM_HIGH = 1\n",
        "    def __init__(self):\n",
        "        np.random.seed(1)\n",
        "        self.hidden_layer0 = np.random.uniform(self.UNIFORM_LOW, np.sqrt(2 / 784), (self.NEURONS, 784))\n",
        "        # print(f\"{self.hidden_layer0 = }\")\n",
        "        self.hidden_layer0_bias = np.random.uniform(self.UNIFORM_LOW, self.UNIFORM_HIGH, (self.NEURONS, 1))\n",
        "        self.hidden_layer1 = np.random.uniform(self.UNIFORM_LOW, self.UNIFORM_HIGH, (self.NEURONS, self.NEURONS))\n",
        "        # print(f\"{self.hidden_layer1 = }\")\n",
        "        self.hidden_layer1_bias = np.random.uniform(self.UNIFORM_LOW, self.UNIFORM_HIGH, (self.NEURONS, 1))\n",
        "        self.output_layer = np.random.uniform(self.UNIFORM_LOW, self.UNIFORM_HIGH, (10, self.NEURONS))\n",
        "        # print(f\"{self.output_layer = }\")\n",
        "        self.output_layer_bias = np.random.uniform(self.UNIFORM_LOW, self.UNIFORM_HIGH, (10, 1))\n",
        "\n",
        "    def forward_propagate(self, x_in):\n",
        "        x_in = np.reshape(x_in, (x_in.shape[0],1))\n",
        "        # print(f\"{x_in = }\")\n",
        "        hidden_layer_0_out = ReLU((np.dot(self.hidden_layer0, x_in)) + self.hidden_layer0_bias)\n",
        "        # print(f\"{self.hidden_layer0 = }\")\n",
        "        # print(f\"{hidden_layer_0_out = }\")\n",
        "        hidden_layer_1_out = ReLU((np.dot(self.hidden_layer1, hidden_layer_0_out)) + self.hidden_layer1_bias)\n",
        "        # print(f\"{self.hidden_layer1 = }\")\n",
        "        # print(f\"{hidden_layer_1_out = }\")\n",
        "        y_pred = softmax((np.dot(self.output_layer, hidden_layer_1_out)) + self.output_layer_bias)\n",
        "        # print(f\"{self.output_layer = }\")\n",
        "        # print(f\"{y_pred = }\")\n",
        "        return hidden_layer_0_out, hidden_layer_1_out, y_pred\n",
        "\n",
        "    def backward_propagate(self, learn_rate, hidden_layer_0_out, hidden_layer_1_out, y_pred, x_train, y_test, l2_lambda):\n",
        "        M = y_test.size\n",
        "        x_train = np.reshape(x_train, (x_train.shape[0], 1))\n",
        "        one_hot_y = one_hot(y_test)\n",
        "\n",
        "        delta_out = y_pred - one_hot_y\n",
        "        delta_h1 = (self.output_layer.T @ delta_out) * deriv_ReLU(hidden_layer_1_out)\n",
        "        delta_h0 = (self.hidden_layer1.T @ delta_h1) * deriv_ReLU(hidden_layer_0_out)\n",
        "\n",
        "        # Compute the gradients\n",
        "        gradient_output_layer = (1 / M) * delta_out @ hidden_layer_1_out.T + (l2_lambda / M) * self.output_layer\n",
        "        gradient_hidden_layer1 = (1 / M) * delta_h1 @ hidden_layer_0_out.T + (l2_lambda / M) * self.hidden_layer1\n",
        "        gradient_hidden_layer0 = (1 / M) * delta_h0 @ x_train.T + (l2_lambda / M) * self.hidden_layer0\n",
        "\n",
        "        # Clip the gradients\n",
        "        # max_grad_value = 0.5  # This value is a hyperparameter you might need to tune\n",
        "        # gradient_output_layer = clip_gradients(gradient_output_layer, max_grad_value)\n",
        "        # gradient_hidden_layer1 = clip_gradients(gradient_hidden_layer1, max_grad_value)\n",
        "        # gradient_hidden_layer0 = clip_gradients(gradient_hidden_layer0, max_grad_value)\n",
        "\n",
        "        # Update the weights using the clipped gradients\n",
        "        self.output_layer -= learn_rate * gradient_output_layer\n",
        "        self.hidden_layer1 -= learn_rate * gradient_hidden_layer1\n",
        "        self.hidden_layer0 -= learn_rate * gradient_hidden_layer0\n",
        "        \n",
        "    def train(self, epochs, learn_rate, x_trains, y_trains, x_tests, y_tests, batch_size=10, l2_lambda=0.01):\n",
        "        for epoch in range(1, epochs, 1):\n",
        "            for i in range(0, x_trains.shape[0], batch_size):\n",
        "                x_batch = x_trains[i:i+batch_size]\n",
        "                y_batch = y_trains[i:i+batch_size]\n",
        "                # Train in batches\n",
        "                for x_train, y_train in zip(x_batch, y_batch):\n",
        "                    h0, h1, y_out = self.forward_propagate(x_train)\n",
        "                    self.backward_propagate(learn_rate, h0, h1, y_out, x_train, y_train, l2_lambda)\n",
        "                predictions = []\n",
        "                for x_test, _ in zip(x_tests, y_tests):\n",
        "                    _, _, y_out = self.forward_propagate(x_test)\n",
        "                    if np.isnan(y_out).any():\n",
        "                        raise ValueError(\"Nan in output\\n\" + str(y_out))\n",
        "                    predictions.append(get_predictions(y_out)[0])\n",
        "                accuracy = get_accuracy(np.array(predictions), y_tests)\n",
        "                print(f\"\\rEpoch: {epoch} (Accuracy: {100 * accuracy :0.2f}%)\", end=\"\")\n",
        "                if accuracy > 0.9:\n",
        "                    print()\n",
        "                    print(\"Reached Accuracy, Saving Model!\")\n",
        "                    return\n",
        "\n",
        "    def get_prediction_as_json(self, x_in):\n",
        "        _, _, out = self.forward_propagate(x_in)\n",
        "        return {str(x): out[x] for x in range(10)}\n",
        "\n",
        "    def test_input(self, index, x_test, y_test):\n",
        "        x = x_test[index]\n",
        "        x.shape += (1,)\n",
        "        _, _, out = self.forward_propagate(x)\n",
        "        pred = get_predictions(out)\n",
        "        print(f\"Prediction : {pred[0]}\\nActual : {y_test[index]}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def save_model(obj, name='mnist_model.pickle'):\n",
        "        with open(name, 'wb') as file:\n",
        "            pk.dump(obj, file)\n",
        "        print(f\"Model {name} Saved!\")\n",
        "\n",
        "    @staticmethod\n",
        "    def load_model(name='mnist_model.pickle'):\n",
        "        with open(name, 'rb') as file:\n",
        "            print(f\"Model {name} loaded.\")\n",
        "            return pk.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "QC9n_2E0pE--"
      },
      "outputs": [],
      "source": [
        "# Set Train Data\n",
        "train_data = pd.concat([pd.read_csv('./polluted_data/train.csv'),pd.read_csv('./data/train.csv')])\n",
        "train_data = np.array(train_data)\n",
        "m, n = train_data.shape\n",
        "np.random.shuffle(train_data)\n",
        "train_data_dev = train_data.T\n",
        "Y_trains = train_data_dev[0]\n",
        "X_trains = train_data_dev[1:n].T\n",
        "X_trains = X_trains / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f2ztPpf56hGw"
      },
      "outputs": [],
      "source": [
        "# Set Test Data\n",
        "test_data = pd.read_csv('./data/mnist_test.csv')\n",
        "test_data = pd.concat([test_data, pd.read_csv('./polluted_data/mnist_test.csv')])\n",
        "test_data = np.array(test_data)\n",
        "m1, n1 = test_data.shape\n",
        "np.random.shuffle(test_data)\n",
        "test_data_dev = test_data.T\n",
        "Y_tests = test_data_dev[0]\n",
        "X_tests = test_data_dev[1:n1].T\n",
        "X_tests = X_tests / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJcEsiJYNoU2",
        "outputId": "ea5ca820-fea1-4796-896b-72ffa72499d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([9, 4, 3, ..., 0, 5, 7], dtype=int64)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "TjjYdsvHpQd1"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "# nn = NeuralNetwork()\n",
        "interrupt_counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "OUVe4ZTl_vPw"
      },
      "outputs": [],
      "source": [
        "epoch_count = 10_000\n",
        "learn_rate = 0.01\n",
        "batch_size = 1000\n",
        "l2_lambda = 0.0003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiBZJeyg-r_a",
        "outputId": "ef6d2f6d-a1ef-4c07-b7f8-c5cd707c88cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch_count = 10000, learn_rate = 0.01, batch_size = 1000, l2_lambda = 0.0003\n",
            "Epoch: 4 (Accuracy: 11.35%)"
          ]
        }
      ],
      "source": [
        "model_name = f\"model_{interrupt_counter}.pickle\"\n",
        "if os.path.exists(model_name):\n",
        "    nn = NeuralNetwork.load_model(model_name)\n",
        "else:\n",
        "    nn = NeuralNetwork()\n",
        "    interrupt_counter = 0\n",
        "try:\n",
        "    print(f\"{epoch_count = }, {learn_rate = }, {batch_size = }, {l2_lambda = }\")\n",
        "    np.random.shuffle(test_data)\n",
        "    test_data_dev = test_data.T\n",
        "    Y_tests = test_data_dev[0]\n",
        "    X_tests = test_data_dev[1:n1].T\n",
        "    X_tests = X_tests / 255\n",
        "    nn.train(epoch_count,learn_rate,X_trains,Y_trains,X_tests,Y_tests, batch_size=batch_size, l2_lambda=l2_lambda)\n",
        "except KeyboardInterrupt as e:\n",
        "    interrupt_counter += 1\n",
        "    print()\n",
        "    print(f\"Pausing training at {model_name}...\")\n",
        "except ValueError as e:\n",
        "    interrupt_counter = 0\n",
        "    print(e)\n",
        "\n",
        "nn.save_model(nn, name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ],
      "source": [
        "# x = np.array([[0.35924991, 0.81438234, 0.80672   , 0.39580896, 0.78656139,\n",
        "#         0.66606848, 0.85239075, 0.11444438, 0.18347001, 0.2011318 ,\n",
        "#         0.66177095, 0.22103212, 0.13258092, 0.34119548, 0.95474173,\n",
        "#         0.49565299, 0.82043591, 0.37857788, 0.77740504, 0.83533551,\n",
        "#         0.74015923, 0.92627585, 0.35261986, 0.61174406, 0.36646459,\n",
        "#         0.50213432, 0.28470452, 0.30681534, 0.40271346, 0.97423887],\n",
        "#        [0.34673833, 0.27358905, 0.66215268, 0.12169938, 0.22637134,\n",
        "#         0.447563  , 0.13716957, 0.77000734, 0.51997415, 0.27636401,\n",
        "#         0.91485431, 0.35950252, 0.50103088, 0.96180632, 0.7488849 ,\n",
        "#         0.36720474, 0.40227126, 0.90528075, 0.99283279, 0.43255661,\n",
        "#         0.78447159, 0.23401017, 0.41827488, 0.48127486, 0.71334866,\n",
        "#         0.82665229, 0.26703485, 0.65300824, 0.674449  , 0.83493142],\n",
        "#        [0.64296124, 0.55791865, 0.28570211, 0.2497653 , 0.17247606,\n",
        "#         0.2508637 , 0.56635266, 0.5870433 , 0.25727518, 0.42454387,\n",
        "#         0.37056349, 0.47786774, 0.15269189, 0.75659268, 0.74777632,\n",
        "#         0.21840999, 0.17226923, 0.86008133, 0.92777535, 0.87996945,\n",
        "#         0.49223198, 0.74574783, 0.11275197, 0.64012699, 0.60324638,\n",
        "#         0.49957939, 0.33833081, 0.10022464, 0.1223997 , 0.94474106],\n",
        "#        [0.28782778, 0.8586247 , 0.67979745, 0.47983673, 0.80073389,\n",
        "#         0.41487942, 0.91120461, 0.1071562 , 0.19339933, 0.18872722,\n",
        "#         0.31377922, 0.53279637, 0.32433066, 0.77386264, 0.43183812,\n",
        "#         0.78540316, 0.7724684 , 0.68649393, 0.38240758, 0.56852594,\n",
        "#         0.17341751, 0.61519227, 0.73899849, 0.62932334, 0.37831265,\n",
        "#         0.87657365, 0.5382955 , 0.22471949, 0.77927106, 0.85580268],\n",
        "#        [0.41790902, 0.68800199, 0.2669509 , 0.12418732, 0.8143539 ,\n",
        "#         0.76599369, 0.84421721, 0.23028548, 0.50565261, 0.8492062 ,\n",
        "#         0.41829619, 0.26910249, 0.94715171, 0.66293384, 0.992613  ,\n",
        "#         0.89074848, 0.80518375, 0.34092644, 0.70241424, 0.94341493,\n",
        "#         0.86827217, 0.18766418, 0.41627882, 0.83143696, 0.85002916,\n",
        "#         0.44142204, 0.31687153, 0.98426207, 0.98248553, 0.58102327],\n",
        "#        [0.32873827, 0.80819802, 0.67257025, 0.50483565, 0.77911132,\n",
        "#         0.13847376, 0.18012337, 0.30008198, 0.88825398, 0.10909787,\n",
        "#         0.93985247, 0.21575092, 0.50281134, 0.49573601, 0.96646676,\n",
        "#         0.55136538, 0.21602155, 0.74050855, 0.12592641, 0.27018857,\n",
        "#         0.60667243, 0.63980893, 0.99530861, 0.95431141, 0.85896458,\n",
        "#         0.50474138, 0.24178954, 0.26622655, 0.44721483, 0.89099666],\n",
        "#        [0.50221851, 0.76042918, 0.94718833, 0.98290949, 0.29698004,\n",
        "#         0.26824745, 0.23925624, 0.47358281, 0.76139402, 0.751783  ,\n",
        "#         0.89066232, 0.782753  , 0.29097717, 0.56314722, 0.59360812,\n",
        "#         0.39211098, 0.42855781, 0.4914807 , 0.85065083, 0.34340315,\n",
        "#         0.6637582 , 0.22887733, 0.54287622, 0.98181773, 0.22060316,\n",
        "#         0.91034899, 0.29022654, 0.55880341, 0.6883957 , 0.73006939],\n",
        "#        [0.33724554, 0.35947668, 0.9232329 , 0.7432118 , 0.10301281,\n",
        "#         0.95361329, 0.84814175, 0.29075088, 0.98515912, 0.12099808,\n",
        "#         0.52068204, 0.60629196, 0.97919631, 0.3570158 , 0.51651664,\n",
        "#         0.98478887, 0.46088296, 0.54486058, 0.9748424 , 0.25831619,\n",
        "#         0.79121022, 0.87223058, 0.72701879, 0.13040422, 0.34531434,\n",
        "#         0.37821878, 0.93368346, 0.32132991, 0.67915276, 0.54057071],\n",
        "#        [0.82955186, 0.89540854, 0.42798417, 0.20672079, 0.72437821,\n",
        "#         0.44983437, 0.3808123 , 0.82048906, 0.68336787, 0.73404236,\n",
        "#         0.85517952, 0.44092122, 0.75493651, 0.37389442, 0.66409759,\n",
        "#         0.20279993, 0.62146772, 0.70360758, 0.30399791, 0.23320118,\n",
        "#         0.4063471 , 0.98878951, 0.15617456, 0.19488063, 0.99586538,\n",
        "#         0.73634718, 0.69586969, 0.11609058, 0.67228301, 0.83697677],\n",
        "#        [0.54854701, 0.57275361, 0.73781451, 0.42024723, 0.6129595 ,\n",
        "#         0.14034209, 0.1022073 , 0.95643268, 0.17798475, 0.64084498,\n",
        "#         0.62024994, 0.12709384, 0.13029494, 0.32105629, 0.84584728,\n",
        "#         0.18047398, 0.10228426, 0.34622783, 0.19931071, 0.49276264,\n",
        "#         0.97129163, 0.70320194, 0.77150675, 0.57799489, 0.70297992,\n",
        "#         0.14799186, 0.22504387, 0.26713752, 0.86837752, 0.35223651]])\n",
        "\n",
        "# y = np.array([[ 794.34835741],\n",
        "#        [ 814.37301254],\n",
        "#        [ 989.69508841],\n",
        "#        [ 747.87486727],\n",
        "#        [ 982.79903332],\n",
        "#        [ 924.53502133],\n",
        "#        [ 998.66777509],\n",
        "#        [ 863.18601651],\n",
        "#        [1002.02453053],\n",
        "#        [ 819.11167586],\n",
        "#        [ 975.83001157],\n",
        "#        [ 926.99422914],\n",
        "#        [1038.5269067 ],\n",
        "#        [ 913.16274961],\n",
        "#        [ 912.37774107],\n",
        "#        [ 813.47935851],\n",
        "#        [ 952.33753563],\n",
        "#        [ 855.15980942],\n",
        "#        [ 842.43387158],\n",
        "#        [ 828.11920047],\n",
        "#        [ 860.63658796],\n",
        "#        [ 839.45020888],\n",
        "#        [ 985.36269363],\n",
        "#        [ 958.98995882],\n",
        "#        [ 841.61818052],\n",
        "#        [ 884.38365779],\n",
        "#        [ 906.53093421],\n",
        "#        [ 963.42998207],\n",
        "#        [ 793.94157442],\n",
        "#        [ 933.32668517]])\n",
        "\n",
        "# # np.exp(993)\n",
        "# print(softmax(np.dot(x, y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGFq9ie3979I"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "def rotate_image(image, angle):\n",
        "    rows, cols = image.shape\n",
        "    M = cv2.getRotationMatrix2D((cols/2,rows/2), angle, 1)\n",
        "    rotated_image = cv2.warpAffine(image, M, (cols, rows))\n",
        "    return rotated_image\n",
        "\n",
        "def add_noise(image, noise_level):\n",
        "    noise = np.random.normal(scale=noise_level, size=image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
        "    return noisy_image\n",
        "\n",
        "def scale_image(image, scale_factor, target_size=(28, 28)):\n",
        "    scaled_image = cv2.resize(image, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # Calculate dimensions of scaled image and padding needed\n",
        "    rows, cols = scaled_image.shape\n",
        "    pad_rows = max(0, (target_size[0] - rows) // 2)\n",
        "    pad_cols = max(0, (target_size[1] - cols) // 2)\n",
        "\n",
        "    # Create padded image with zeros\n",
        "    padded_image = np.zeros(target_size, dtype=scaled_image.dtype)\n",
        "\n",
        "    # Calculate coordinates for pasting scaled image\n",
        "    paste_start_row = max(0, (rows - target_size[0]) // 2)\n",
        "    paste_end_row = min(rows, paste_start_row + target_size[0])\n",
        "    paste_start_col = max(0, (cols - target_size[1]) // 2)\n",
        "    paste_end_col = min(cols, paste_start_col + target_size[1])\n",
        "\n",
        "    # Paste scaled image onto padded image\n",
        "    padded_image[pad_rows:pad_rows + rows, pad_cols:pad_cols + cols] = scaled_image[paste_start_row:paste_end_row, paste_start_col:paste_end_col]\n",
        "\n",
        "    return padded_image\n",
        "\n",
        "def modify_image(image, rotation, noise, scale):\n",
        "    modified_image = rotate_image(image, rotation)\n",
        "    modified_image = add_noise(modified_image, noise)\n",
        "    modified_image = scale_image(modified_image, scale)\n",
        "    return modified_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4-_B4TJnmC3",
        "outputId": "8f3119ec-f1db-4c25-96fe-c03f3ec410b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mnist_test.csv mnist_train.csv small_train.csv train.csv\n",
            "starting on polluting mnist_test.csv (10000, 785)\n",
            "done on polluting mnist_test.csv\n",
            "starting on polluting mnist_train.csv (60000, 785)\n",
            "done on polluting mnist_train.csv\n",
            "starting on polluting small_train.csv (2, 785)\n",
            "done on polluting small_train.csv\n",
            "starting on polluting train.csv (42000, 785)\n",
            "done on polluting train.csv\n"
          ]
        }
      ],
      "source": [
        "dataset_to_pollute = os.listdir('./data')\n",
        "print(*dataset_to_pollute)\n",
        "new_dataset_path = \"./polluted_data/{file_name}\"\n",
        "for dataset in dataset_to_pollute:\n",
        "    original = pd.read_csv(f'./data/{dataset}')\n",
        "    new_dataset = pd.DataFrame(columns=list(original.columns))\n",
        "    print(\"starting on polluting\", dataset, original.shape)\n",
        "    for i in range(original.shape[0]):\n",
        "        try:\n",
        "            label, x_in = original.loc[i].values[0], original.loc[i].values[1:]\n",
        "            x_in = x_in.reshape(28,28)\n",
        "            rotation = random.randint(0,180)  # Rotation angle in degrees\n",
        "            noise = random.randint(0,30)  # Noise level\n",
        "            scale = random.random() + 0.5 # Scaling factor\n",
        "            x_in = modify_image(np.array(x_in, dtype=np.uint8), rotation, noise, scale)\n",
        "            x_in = x_in.flatten()\n",
        "            new_row = [label] + x_in.tolist()\n",
        "            new_dataset.loc[i] = new_row\n",
        "        except KeyError as e:\n",
        "            print(f\"error in file {dataset} at row {i}\")\n",
        "            break\n",
        "    print(\"done on polluting\", dataset)\n",
        "    new_dataset.to_csv(new_dataset_path.format(file_name=dataset), index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
